# -*- coding: utf-8 -*-
"""app

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15DvxYbGJHYnef58RV_cBnebXVqwxNkRQ
"""

import streamlit as st
import os
import google.generativeai as genai
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_google_genai import GoogleGenerativeAIEmbeddings
from langchain.schema import HumanMessage

# Set up the environment variable for API key
os.environ["GOOGLE_API_KEY"] = st.secrets["GOOGLE_API_KEY"]
os.environ["PINECONE_API_KEY"] = st.secrets["PINECONE_API_KEY"]

genai.configure(api_key=os.environ["GOOGLE_API_KEY"])

# Initialize the chat model
model = ChatGoogleGenerativeAI(model="models/gemini-1.0-pro-latest",
                               temperature=0.3, top_p=0.2)

# Initialize context
context = [HumanMessage(content='Your role is an assistant for an ADHD specialist clinic called ADHD Specialists Australia to answer questions people have regarding the clinic and ADHD. You first welcome me and ask how you can help me.')]
response = model(context)
context.append(response)

# Streamlit app layout
st.title("ADHD Specialist Australia Clinic Chatbot")

if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

st.markdown(response.content)

def augment_prompt_qa(query: str):
    # get top 3 results from knowledge base
    results = vectorstore_qa2.similarity_search(query, k=3)

    # get the text from the results
    source_knowledge = "\n".join([x.page_content for x in results])

    # feed into an augmented prompt
    augmented_prompt = f"""Using the contexts below, answer the query.

    Contexts:
    {source_knowledge}

    Query: {query}"""
    return augmented_prompt

query = st.text_input("Your query:")

if query:
    human_message = HumanMessage(content=query)
    new_context = HumanMessage(content=augment_prompt_qa(query))
    context.append(new_context)
    context.append(human_message)
    st.session_state.chat_history.append(human_message)

    response = model(context)
    context.append(response)
    st.session_state.chat_history.append(response)

    st.markdown(response.content)

for message in st.session_state.chat_history:
    st.markdown(message.content)
